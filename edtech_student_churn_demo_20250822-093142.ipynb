{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b258330",
   "metadata": {},
   "source": [
    "\n",
    "# EdTech â€” Student Churn / Dropout Risk (Ready-to-Demo)\n",
    "\n",
    "**Goal:** Identify students likely to stop using the platform (churn) so the product/CS team can intervene with targeted actions (mentoring, reminders, offers).\n",
    "\n",
    "This notebook generates **synthetic student engagement data** and walks through:\n",
    "- Data generation & EDA\n",
    "- Feature engineering for engagement signals\n",
    "- Baseline models (Logistic Regression, Random Forest)\n",
    "- Model evaluation (confusion matrix, ROC AUC)\n",
    "- Client-friendly interpretation and recommended actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef52a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb139b2",
   "metadata": {},
   "source": [
    "## 1) Generate synthetic student engagement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25939ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dataset\n",
    "rng = np.random.default_rng(42)\n",
    "n_students = 1600\n",
    "\n",
    "students = pd.DataFrame({\n",
    "    'student_id': np.arange(1, n_students+1),\n",
    "    'signup_date': pd.to_datetime('2023-01-01') + pd.to_timedelta(rng.integers(0, 700, n_students), unit='D'),\n",
    "    'country': rng.choice(['US','IN','UK','CA','AU'], size=n_students, p=[0.4,0.25,0.15,0.12,0.08]),\n",
    "    'cohort': rng.choice(['A','B','C','D'], size=n_students)\n",
    "})\n",
    "\n",
    "# Engagement features (synthetic)\n",
    "lessons_completed_week = np.clip(rng.normal(3.2, 1.6, n_students), 0, None)\n",
    "days_since_last_login = np.clip(rng.normal(9, 7, n_students), 0, None).astype(int)\n",
    "practice_streak_days = np.clip(rng.normal(12, 9, n_students), 0, None).astype(int)\n",
    "avg_quiz_score = np.clip(rng.normal(70, 14, n_students), 0, 100)\n",
    "received_mentor_msg = rng.binomial(1, 0.3, n_students)\n",
    "time_spent_minutes_week = np.clip(rng.normal(180, 80, n_students), 10, None)\n",
    "\n",
    "# Synthetic churn generation (probability model)\n",
    "logit = (\n",
    "    -1.0\n",
    "    - 0.25*lessons_completed_week\n",
    "    + 0.06*days_since_last_login\n",
    "    - 0.02*practice_streak_days\n",
    "    - 0.015*avg_quiz_score\n",
    "    - 0.6*received_mentor_msg\n",
    "    - 0.001*time_spent_minutes_week\n",
    ")\n",
    "p = 1/(1+np.exp(-logit))\n",
    "churn = rng.binomial(1, p)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'student_id': students['student_id'],\n",
    "    'signup_date': students['signup_date'],\n",
    "    'country': students['country'],\n",
    "    'cohort': students['cohort'],\n",
    "    'lessons_completed_week': lessons_completed_week,\n",
    "    'days_since_last_login': days_since_last_login,\n",
    "    'practice_streak_days': practice_streak_days,\n",
    "    'avg_quiz_score': avg_quiz_score,\n",
    "    'received_mentor_msg': received_mentor_msg,\n",
    "    'time_spent_minutes_week': time_spent_minutes_week,\n",
    "    'churned_next_month': churn\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069584f8",
   "metadata": {},
   "source": [
    "## 2) Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5629271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot churn distribution\n",
    "plt.figure()\n",
    "df['churned_next_month'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Churn vs Keep (counts)')\n",
    "plt.xlabel('churned_next_month')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43198953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature distributions (few)\n",
    "for col in ['lessons_completed_week','days_since_last_login','practice_streak_days','avg_quiz_score','time_spent_minutes_week']:\n",
    "    plt.figure()\n",
    "    df[col].hist(bins=30)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f723c29",
   "metadata": {},
   "source": [
    "**Inference (EDA):**\n",
    "- Check which students have low engagement (lessons, time spent) and high days since last login. These are likely to churn.\n",
    "- Mentor messages correlate with retention; promoting mentor contact may reduce churn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e46aa",
   "metadata": {},
   "source": [
    "## 3) Feature engineering & Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['lessons_completed_week','days_since_last_login','practice_streak_days','avg_quiz_score','received_mentor_msg','time_spent_minutes_week']\n",
    "X = df[features].copy()\n",
    "y = df['churned_next_month'].copy()\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale numeric features for logistic regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "proba_lr = lr.predict_proba(X_test_scaled)[:,1]\n",
    "pred_lr = (proba_lr >= 0.5).astype(int)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "proba_rf = rf.predict_proba(X_test)[:,1]\n",
    "pred_rf = (proba_rf >= 0.5).astype(int)\n",
    "\n",
    "print('Logistic Regression:')\n",
    "print(classification_report(y_test, pred_lr))\n",
    "print('ROC AUC (LR):', round(roc_auc_score(y_test, proba_lr),3))\n",
    "\n",
    "print('\\nRandom Forest:')\n",
    "print(classification_report(y_test, pred_rf))\n",
    "print('ROC AUC (RF):', round(roc_auc_score(y_test, proba_rf),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289f7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, proba_lr)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, proba_rf)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_lr, tpr_lr, label='Logistic Regression')\n",
    "plt.plot(fpr_rf, tpr_rf, label='Random Forest')\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f90f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for Random Forest\n",
    "cm = confusion_matrix(y_test, pred_rf)\n",
    "print('Confusion matrix (RF):\\n', cm)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Confusion Matrix (RF)')\n",
    "plt.colorbar()\n",
    "for (i, j), v in np.ndenumerate(cm):\n",
    "    plt.text(j, i, str(v), ha='center', va='center')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c07c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest\n",
    "importances = rf.feature_importances_\n",
    "fi = pd.DataFrame({'feature': features, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab50d7bc",
   "metadata": {},
   "source": [
    "**Inference (Model Results):**\n",
    "- The model successfully separates at-risk students based on engagement.\n",
    "- Important signals often include: lessons completed, days since last login, time spent, and mentor contact.\n",
    "- Use model scores to create 'early warning' lists for the student success team.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04409425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold tuning table (precision vs recall)\n",
    "thresholds = [0.2,0.3,0.4,0.5,0.6,0.7]\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    pred = (proba_rf >= t).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, pred, average='binary', zero_division=0)\n",
    "    rows.append({'threshold': t, 'precision': round(precision,3), 'recall': round(recall,3), 'f1': round(f1,3)})\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0784bb8",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Actionable Playbook (What to tell the client)\n",
    "\n",
    "- **Weekly early-warning list:** Run the model weekly and send top N at-risk students to Student Success for outreach.  \n",
    "- **Personalized interventions:** For students with low quiz scores, offer mini-tutorials; for those with low activity, send re-engagement emails or mentor sessions.  \n",
    "- **Measure results:** Track whether interventions reduce subsequent churn (A/B test recommended).  \n",
    "- **Data to add later for better accuracy:** course progress, assignment submissions, in-app events, message response times.\n",
    "\n",
    "**Next steps to production:** Replace synthetic data with real exports, retrain model, and serve via simple API or integrate with CRM.  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
